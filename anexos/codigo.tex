% \appendix
\chapter{Código Fuente del Proyecto}\label{apx:source}
\section{Control de Actuadores en Tiempo Real}
\begin{lstlisting}[title={main.cpp},language=c++]
#include <mbed.h>
#include <Servo.h>
#include <Motor.h>
#include <ros.h>

// ros msgs
#include <geometry_msgs/Twist.h> // sub to Twist message for control
#include <sensor_msgs/Range.h>   // pub to Range message for sensor

DigitalOut led(D13);

Servo steering(D9);            // steering servo
Motor motor(D12, D10, D11); // motor driver

// ROS part
// software utils
Timer t;
Ticker pub_ticker;
// ros part
ros::NodeHandle nh;

// messages
geometry_msgs::Twist control_cmd; // control command is of type twist

// callback prototypes
void ctrlCommandCb(const geometry_msgs::Twist &command);

// subscribers
// ros subscriber for control command
ros::Subscriber<geometry_msgs::Twist> ctrlSub("cmd_vel", ctrlCommandCb);

// prototypes 
// callbacks
void ctrlCommandCb(const geometry_msgs::Twist &command);

int main() {
    
    motor.period(0.0005);     // frecuencia 2 Khz
    steering = 0;
    // init sensors
    led = 1;
    // ros initialization
    nh.initNode();
    nh.subscribe(ctrlSub);
    //
    led = 0;

    while(1) {
        nh.spinOnce();
        wait_ms(1);
    }
}

// control command callback
void ctrlCommandCb(const geometry_msgs::Twist &command)
{
    led = !led;
    float linear = command.linear.x;
    float angular = command.angular.z / 2 + 0.5; // (command.angular.z * 0.35) + 0.32;
    steering = angular;
    // testigo = abs(linear * 8);
    motor.speed(linear);
}
\end{lstlisting}

\section{Script de entrenamiento}
\begin{lstlisting}[title={train\_model.py},language=Python]
from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array

from keras.models import model_from_json
    
import numpy as np
import pandas as pd
import bcolz
import threading
    
from time import time
import os
import sys
import glob
import shutil

from sklearn.model_selection import train_test_split
    
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras import backend as K
from keras.callbacks import TensorBoard, ModelCheckpoint
    
from keras.utils import plot_model
import models
from utils import *
    
class RobocarTrainer(object):
        
    # data for training
    input_shape=(224,224,3)
    im_shape = (224, 224)
    
    # train parameters
    batch_size = 32
    n_epochs = 100
    
    def __init__(self, model_name, model_path, dataset_path, log_path='trainlogs'):
        self.model_name = model_name
        self.model_path = model_path
        self.log_path = log_path
        self.dataset_path = dataset_path
            
        # creating callbacks
        self.tfBoardCB = TensorBoard('{}/{}_{}'.format(self.log_path, model_name, time()), write_graph=True)
    
        filepath= model_path + model_name + '_best.h5'
    
        self.checkpointCB = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')
    
        
    def LoadDataset(self):
    
        print('loading dataset...')
        self.dataset = pd.read_csv(self.dataset_path + 'target.csv')
    
        self.dataset['imgpath'] = self.dataset.id.apply(file_path_from_db_id, args=("%d.bmp", self.dataset_path))
    
        self.train, self.test = train_test_split(self.dataset, test_size=0.2)
        self.valid, self.test = train_test_split(self.test, test_size=0.7)
        
        self.train_steps = int(self.train.shape[0] / self.batch_size)
        self.valid_steps = int(self.valid.shape[0] / self.batch_size)
        self.test_steps = int(self.test.shape[0] / self.batch_size)
        print('dataset loaded!')
    
    def Train(self):
    
        print('loading model...')
        self.model = models.vanilla(self.input_shape)
        self.model.summary()
        model_json = self.model.to_json()
        with open(self.model_path + self.model_name + '.json', "w") as json_file:
                json_file.write(model_json)
                
        plot_model(self.model, to_file=self.model_name + '.png', show_shapes=True)
        print('dataset size: ', self.train.shape[0],
                    'train_steps: ', self.train_steps, 
                    'valid steps: ', self.valid_steps, 
                    'test_steps: ', self.test_steps)
            
        print('hiperparameters:')
        print('batch size:{}'.format(self.batch_size))
            
    
        print('training...')
        self.model.fit_generator(
                                generator_from_df(self.train, self.batch_size, self.im_shape, 'angular'),
                                steps_per_epoch=self.train_steps, 
                                epochs=self.n_epochs,
                                validation_data=generator_from_df(self.valid, self.batch_size, self.im_shape, 'angular'),
                                validation_steps=self.valid_steps,
                                callbacks=[self.tfBoardCB, self.checkpointCB],
                                verbose=2
                                )
        print('finished training')
        self.score = self.model.evaluate_generator(
                                generator_from_df(self.test, self.batch_size, self.im_shape, 'angular'), 
                                steps=self.test_steps
                                )
        print('loss: ', self.score)
    
    def SaveModel(self):
        # serialize model to JSON
        self.model_json = self.model.to_json()
        with open(self.model_name + '.json', "w") as json_file:
                json_file.write(self.model_json)
        # serialize weights to HDF5
        self.model.save_weights(self.model_name + '.h5')
        print("Saved model to disk")
    
    
    
    
if __name__ == '__main__':
        
    import argparse
    parser = argparse.ArgumentParser(description='Entrenamiento de una red neuronal convolucional')
    parser.add_argument("model_name", help="name of the model to train")
    parser.add_argument("model_path", help="path where the model files will be saved")
    parser.add_argument("dataset_path", help="path where the the dataset is saved")
        
    args = parser.parse_args()
        
    trainer = RobocarTrainer(args.model_name, args.model_path, args.dataset_path)
    trainer.LoadDataset()
    trainer.Train()
    trainer.SaveModel()

\end{lstlisting}

\section{Sincronización de Mensajes}

\begin{lstlisting}[title={msg\_sync.py},language=Python]
    from keras.preprocessing.image import load_img
    from keras.preprocessing.image import img_to_array
    
    from keras.models import model_from_json
        
    import numpy as np
    import pandas as pd
    import bcolz
    import threading
        
    from time import time
    import os
    import sys
    import glob
    import shutil
    
    from sklearn.model_selection import train_test_split
        
    from keras.models import Sequential
    from keras.layers import Dense, Dropout, Flatten
    from keras.layers import Conv2D, MaxPooling2D
    from keras import backend as K
    from keras.callbacks import TensorBoard, ModelCheckpoint
        
    from keras.utils import plot_model
    import models
    from utils import *
        
    class RobocarTrainer(object):
            
        # data for training
        input_shape=(224,224,3)
        im_shape = (224, 224)
        
        # train parameters
        batch_size = 32
        n_epochs = 100
        
        def __init__(self, model_name, model_path, dataset_path, log_path='trainlogs'):
            self.model_name = model_name
            self.model_path = model_path
            self.log_path = log_path
            self.dataset_path = dataset_path
                
            # creating callbacks
            self.tfBoardCB = TensorBoard('{}/{}_{}'.format(self.log_path, model_name, time()), write_graph=True)
        
            filepath= model_path + model_name + '_best.h5'
        
            self.checkpointCB = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')
        
            
        def LoadDataset(self):
        
            print('loading dataset...')
            self.dataset = pd.read_csv(self.dataset_path + 'target.csv')
        
            self.dataset['imgpath'] = self.dataset.id.apply(file_path_from_db_id, args=("%d.bmp", self.dataset_path))
        
            self.train, self.test = train_test_split(self.dataset, test_size=0.2)
            self.valid, self.test = train_test_split(self.test, test_size=0.7)
            
            self.train_steps = int(self.train.shape[0] / self.batch_size)
            self.valid_steps = int(self.valid.shape[0] / self.batch_size)
            self.test_steps = int(self.test.shape[0] / self.batch_size)
            print('dataset loaded!')
        
        def Train(self):
        
            print('loading model...')
            self.model = models.vanilla(self.input_shape)
            self.model.summary()
            model_json = self.model.to_json()
            with open(self.model_path + self.model_name + '.json', "w") as json_file:
                    json_file.write(model_json)
                    
            plot_model(self.model, to_file=self.model_name + '.png', show_shapes=True)
            print('dataset size: ', self.train.shape[0],
                        'train_steps: ', self.train_steps, 
                        'valid steps: ', self.valid_steps, 
                        'test_steps: ', self.test_steps)
                
            print('hiperparameters:')
            print('batch size:{}'.format(self.batch_size))
                
        
            print('training...')
            self.model.fit_generator(
                                    generator_from_df(self.train, self.batch_size, self.im_shape, 'angular'),
                                    steps_per_epoch=self.train_steps, 
                                    epochs=self.n_epochs,
                                    validation_data=generator_from_df(self.valid, self.batch_size, self.im_shape, 'angular'),
                                    validation_steps=self.valid_steps,
                                    callbacks=[self.tfBoardCB, self.checkpointCB],
                                    verbose=2
                                    )
            print('finished training')
            self.score = self.model.evaluate_generator(
                                    generator_from_df(self.test, self.batch_size, self.im_shape, 'angular'), 
                                    steps=self.test_steps
                                    )
            print('loss: ', self.score)
        
        def SaveModel(self):
            # serialize model to JSON
            self.model_json = self.model.to_json()
            with open(self.model_name + '.json', "w") as json_file:
                    json_file.write(self.model_json)
            # serialize weights to HDF5
            self.model.save_weights(self.model_name + '.h5')
            print("Saved model to disk")
        
        
        
        
    if __name__ == '__main__':
            
        import argparse
        parser = argparse.ArgumentParser(description='Entrenamiento de una red neuronal convolucional')
        parser.add_argument("model_name", help="name of the model to train")
        parser.add_argument("model_path", help="path where the model files will be saved")
        parser.add_argument("dataset_path", help="path where the the dataset is saved")
            
        args = parser.parse_args()
            
        trainer = RobocarTrainer(args.model_name, args.model_path, args.dataset_path)
        trainer.LoadDataset()
        trainer.Train()
        trainer.SaveModel()
    
    \end{lstlisting}

\section{Aumentación de datos}

\begin{lstlisting}[title={augmentation.py},language=Python]
    from keras.preprocessing.image import load_img, ImageDataGenerator
    from keras.preprocessing.image import img_to_array
    
    from pandas.plotting import bootstrap_plot
    import numpy as np
    import pandas as pd
    import bcolz
    import threading
    
    import cv2
    
    from utils import *
    
    import os
    import sys
    import glob
    import shutil
    import matplotlib.pyplot as plt
    get_ipython().magic(u'matplotlib inline')
    
    dataset1 = pd.read_csv('../../datasets/dataset/target.csv')
    dataset1['imgpath'] = dataset1.id.apply(file_path_from_db_id)
    
    datagen = ImageDataGenerator(
            rotation_range=20,
            height_shift_range=0.2,
            shear_range=0.15,
            zoom_range=0.15,
            fill_mode='nearest')
    
    test_gen = batch_generator(dataset1, 1, (224,224), 'angular', process=False, shuffle=False)
    img, tg = test_gen.next()
    img = img[0]
    img = (img)*255
    plt.subplot(131)
    plt.imshow(img)
    
    for i, row in dataset1.sample(1).iterrows():
        img3 = img_to_array(load_img(row['imgpath']))
    
    plt.subplot(132)
    plt.imshow(img3*255)
    
    img2, tg2 = horizontal_flip(img, tg)
    plt.subplot(133)
    plt.imshow(img2)
    
    datagen = ImageDataGenerator(
            rotation_range=20,
            height_shift_range=0.2,
            shear_range=0.15,
            zoom_range=0.15,
            fill_mode='nearest')
    
    test_gen = batch_generator(dataset1, 1, (224,224), 'angular', process=False, shuffle=False)
    
    offset = dataset1.shape[0] + 1
    id_offset = dataset1['id'].max() + 1
    i = 0
    newData = []
    for idx, row in dataset1.iterrows():
        # generador auxiliar
        
        ### extraemos la imagen en una variable auxiliar
        img = img_to_array(load_img(row['imgpath']))
        target = row['angular']
        ### aplicamos la transformacion de acuerdo a ciertas condiciones
        ## si es cero, o muy cercano a 0 no aplicamos la transformacion
        if np.abs(target) > 0.09:
            ## transformacion horizontal
            hImg, hTarget = horizontal_flip(img, target) 
            # guardar imagen y entry en el dataframe
            filename = "dataset/" + str(id_offset + i) + ".bmp";
            hImg = cv2.cvtColor(hImg,cv2.COLOR_BGR2RGB)
            cv2.imwrite(filename, hImg)
            newData.append([(id_offset + i), 
                            row['linear'], 
                            hTarget,
                            filename])
            # incrementa indice para siguiente entrada
            i += 1
            
            ## transformacion aleatoria
            choice = np.random.choice([0,1])
            if choice == 1:
                rImg = datagen.flow(img.reshape((1,) + img.shape),y=None, batch_size=1).next()
                rImg = rImg[0]
                # guardar imagen y entry en el dataframe
                filename = "dataset/" + str(id_offset + i) + ".bmp";
                rImg = cv2.cvtColor(rImg,cv2.COLOR_BGR2RGB)
                cv2.imwrite(filename, rImg)
                newData.append([(id_offset + i), 
                                row['linear'], 
                                target,
                                filename])
                # incrementa indice para siguiente entrada
                i += 1
 
        ### guardamos la imagen en el directorio y el nuevo target en el d
    columns = ['id', 'linear', 'angular', 'imgpath']
    newDataset = pd.DataFrame(newData, columns=columns)
    
    
    newDataset = pd.DataFrame(newData, columns=columns)
    
    dataset = dataset1.append(newDataset, ignore_index=True)
    dataset.to_csv('augmented.csv')
    \end{lstlisting}

\section{Generación de datos}
\begin{lstlisting}[title={utils.py},language=Python]
    from keras.preprocessing.image import load_img
    from keras.preprocessing.image import img_to_array
    
    from keras.models import model_from_json
    
    import numpy as np
    import pandas as pd
    import bcolz
    import threading
    
    import cv2
    
    import os
    import sys
    import glob
    import shutil
    
    from sklearn.model_selection import train_test_split
    
    import models
    
    def generator_from_df(df, batch_size, target_size, target_column='target', features=None, process=True):
        print('generating minibatch!')
        nbatches, n_skipped_per_epoch = divmod(df.shape[0], batch_size)
        #print nbatches
        count = 1
        epoch = 0
        # New epoch.
        while 1:
            df = df.sample(frac=1) # shuffle in every epoch
            epoch += 1
            i, j = 0, batch_size
            # Mini-batches within epoch.
            mini_batches_completed = 0
            for _ in range(nbatches):
                sub = df.iloc[i:j]
                try:
                    if process == True:
                        X = np.array([(2 * (img_to_array(load_img(f, target_size=target_size)) / 255.0 - 0.5)) for f in sub.imgpath])
                    else:
                        X = np.array([((img_to_array(load_img(f, target_size=target_size)))) for f in sub.imgpath])
                        
                    Y = sub[target_column].values
                    # Simple model, one input, one output.
                    mini_batches_completed += 1
                    print ".",
                    
                    yield X, Y
    
                except IOError as err:
                    count -= 1
    
                i = j
                j += batch_size
                count += 1
    
\end{lstlisting}

\section{Nodo de Inferencia}

\begin{lstlisting}[title={neural\_node.py},language=Python]
#!/usr/bin/env python
from __future__ import print_function
import roslib
import rospkg
roslib.load_manifest('robocar')
import sys
import csv
import numpy as np
import rospy
import cv2
import message_filters
from std_msgs.msg import String, Float32
from sensor_msgs.msg import Image, Range, CompressedImage, Joy
from geometry_msgs.msg import Twist, TwistStamped
from cv_bridge import CvBridge, CvBridgeError

from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array

from keras.models import model_from_json

import pandas as pd
import threading

import tensorflow as tf
import os
import sys
import glob
import shutil

from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras import backend as K
from keras.callbacks import TensorBoard, ModelCheckpoint

from keras.utils import plot_model
import models
from models import custom_loss
import imutils

class AutoPilot:
    idx = 0
    
    dim = (224, 224)

    linear = 0
    angular_joy = 0

    def __init__(self, folder):
        rospack = rospkg.RosPack()
        pack_path = rospack.get_path('robocar')
        model_path = pack_path + '/scripts/simple2'
        
        # get ros params
        self.img_topic = rospy.get_param('img_topic', default='/camera/image/compressed')
        self.output_topic = rospy.get_param('output_topic', default='/neural_output')
        self.model_name = rospy.get_param('model', default=model_path)

        ## cargar la red neuronal en la memoria 
        # load json and create model
        json_file = open(self.model_name + '.json', 'r')
        loaded_model_json = json_file.read()
        json_file.close()
        self.model = model_from_json(loaded_model_json)

        # load weights into new model
        self.model.load_weights(self.model_name + "_best.h5")
        print("Loaded model from disk") 
        self.model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])
        self.model.summary()
        self.graph = tf.get_default_graph()

        print('creando subs y pubs...')
        # image subscriber for the predictor
        self.image_sub = rospy.Subscriber(self.img_topic, CompressedImage, self.imCallback, queue_size=1)
        
        # float32 publisher for output 
        self.output_pub = rospy.Publisher(self.output_topic, Float32, queue_size=1)
    
    #this callback executes when the two subscribers sync
    def imCallback(self, img):
        """ este calback lee la imagen de la camara, la preprocesa y obtiene 
        una prediccion para el comando de control del robot"""

        # lee la imagen y la preprocesa
        np_image = cv2.imdecode(np.fromstring(img.data, np.uint8),cv2.IMREAD_COLOR)
        np_image = cv2.resize(np_image, self.dim, interpolation = cv2.INTER_AREA)
        #print (np_image.shape)
        np_image = (2 * (np_image / 255.0 - 0.5))
        x = np_image.reshape((1,) + np_image.shape)  # this is a Numpy array with shape (1, h,w, c)
        #print (x.shape)
        # obtiene la prediccion de la red neuronal
        angular = 0.0
        with self.graph.as_default():
            angular = self.model.predict(x, batch_size=1, verbose=0)

        angular = np.asscalar(angular.flatten())
        #print ("prediccion: ", angular)
        # crea el mensaje para el control del carro y publica 
        # msg = Twist()
        
        # msg.angular.z = angular
        # self.twist_pub.publish(msg)

        output_msg = Float32()
        output_msg.data = angular
        self.output_pub.publish(output_msg)

        
def main(args):
    rospy.init_node('neural_node', anonymous=True)
    stamper = AutoPilot(None)

    try:
        rospy.spin()
    except KeyboardInterrupt:
        print("shutting down")
    cv2.destroyAllWindows()

if __name__ == '__main__':
    main(sys.argv)

\end{lstlisting}

\section{Nodo de detección de obstáculos}
\begin{lstlisting}[title={obstacle\_node.py},language=Python]
    #!/usr/bin/env python
    from __future__ import print_function
    import roslib
    import rospkg
    import rospy
    roslib.load_manifest('robocar')
    
    from sensor_msgs.msg import Range
    from std_msgs.msg import Float32
    import sys
    import csv
    
    class ObstacleDetector:
        idx = 0
        # model_name = '/home/pepe/catkin_ws/src/robocar/scripts/simple2'
        dim = (224, 224)
    
        linear = 0
        angular_joy = 0
        max_acc = 0.3
    
        kp = 4.0
    
        def __init__(self, folder):
            # get ros params
            rospy.loginfo("Obstacle node init")
            self.range_topic = rospy.get_param('range_topic', default='/laser')
            self.output_topic = rospy.get_param('output_topic', default='/obstacle_output')
            self.stop_distance = rospy.get_param('stop_distance', default=0.15)
            # input subscriber for the predictor
            self.range_sub = rospy.Subscriber(self.range_topic, Range, self.RangeCallback, queue_size=1)
            
            # float32 publisher for output 
            self.output_pub = rospy.Publisher(self.output_topic, Float32, queue_size=1)
        
        #this callback executes when the two subscribers sync
        def RangeCallback(self, msg):
            """ este calback recibe el rango del sensor y calcula la salida 
            correspondiente
            """
            error = msg.range - self.stop_distance
            error = error * 2 if error < 0 else error 
            
            acceleration = self.kp * error
            acceleration = self.max_acc if acceleration > self.max_acc else acceleration
            acceleration = -self.max_acc * 2 if acceleration < -self.max_acc else acceleration
            acceleration = 0 if (acceleration < (self.stop_distance + 0.03)) and (acceleration > (self.stop_distance - 0.01)) else acceleration
    
            out_msg = Float32()
            out_msg.data = acceleration
            self.output_pub.publish(out_msg)
        
    def main(args):
        rospy.init_node('neural_node', anonymous=True)
        stamper = ObstacleDetector(None)
        rospy.spin()
       
    if __name__ == '__main__':
        main(sys.argv)
    
\end{lstlisting}

\section{Piloto Automático}

\begin{lstlisting}[title={pilot\_node.cpp},language=c++]
    #include <ros/ros.h>
    #include <boost/thread.hpp>
    #include <std_msgs/Float32.h>
    
    #include <std_msgs/String.h>
    #include <geometry_msgs/Twist.h>
    #include <geometry_msgs/TwistStamped.h>
    #include <sensor_msgs/Joy.h>
    
    #include <cmath>
    
    class Pilot
    {
    
      private:
        // data
        bool manual_;
        // topics from param server
        std::string neural_topic_;
        std::string obstacle_topic_;
        std::string joy_twist_topic_;
    
        std::string output_topic_;
    
        int freq_hz_;
        // messages
        geometry_msgs::Twist twist_msg_;          // simple twist message from joystick
        geometry_msgs::Twist manual_twist_msg_;          // simple twist message from joystick
        // geometry_msgs::TwistStamped stamped; // stamped twist for sync
    
        // subs and PUbs
        ros::Subscriber neural_sub_;
        ros::Subscriber obstacle_sub_;
        ros::Subscriber joy_twist_sub_;
    
        ros::Publisher twist_cmd_pub_;
    
        // subs callback
        // for neural steering
        void NeuralCallback(const std_msgs::Float32::ConstPtr &steering);
    
        // for obsTacle nOde
        void ObstacleCallback(const std_msgs::Float32::ConstPtr &acceleration);
    
        // for joy tELeop
        void JoyTwistCallback(const geometry_msgs::Twist::ConstPtr &joy_twist);
    
        // for find object 2d
        void ObjectCallback(const std_msgs::Float32::ConstPtr &steering);
    
      public:
        Pilot();
    
        ros::Timer timer;
    
        ros::NodeHandle nh_;
        void TimerCallback(const ros::TimerEvent &event);
        float GetInterval();
    };
    // constructor
    Pilot::Pilot() : manual_(false)
    {
        ROS_INFO("Iniciando nodos");
    
        nh_.param<int>("freq_hz", freq_hz_, 20);
        if (freq_hz_ <= 0)
        {
            ROS_WARN("Invalid frequency value, default: 20Hz");
            freq_hz_ = 20;
        }

        // messages are received in QUEues
        nh_.param<std::string>("neural_topic", neural_topic_, "/neural_output");
        nh_.param<std::string>("obstacle_topic", obstacle_topic_, "/obstacle_output");
        nh_.param<std::string>("joy_twist_topic", joy_twist_topic_, "/joy_cmd_vel");
    
        nh_.param<std::string>("output_topic", output_topic_, "/cmd_vel");
        
        // subscribe to nodes
        ROS_INFO("Creando subs y pubs");
        neural_sub_ = nh_.subscribe<std_msgs::Float32>(neural_topic_, 1, &Pilot::NeuralCallback, this);
        obstacle_sub_ = nh_.subscribe<std_msgs::Float32>(obstacle_topic_, 1, &Pilot::ObstacleCallback, this);
        joy_twist_sub_ = nh_.subscribe<geometry_msgs::Twist>(joy_twist_topic_, 1, &Pilot::JoyTwistCallback, this);

        // output topic por piLOt node
        twist_cmd_pub_ = nh_.advertise<geometry_msgs::Twist>(output_topic_, 1);
    
    }
    
    float Pilot::GetInterval()
    {
        return 1.0 / freq_hz_;
    }
    
    ///////////////////////////////////////
    // CALLBACKS //////////////////////////
    ///////////////////////////////////////
    
    void Pilot::NeuralCallback(const std_msgs::Float32::ConstPtr &steering)
    {
        // extract the command
        // put in the message
        // double angular = steering;
        twist_msg_.angular.z = steering->data;
    }
    
    void Pilot::ObstacleCallback(const std_msgs::Float32::ConstPtr &acceleration)
    {
        // double LinEAr = acceleration;
        twist_msg_.linear.x = acceleration->data;
    }
    
    void Pilot::JoyTwistCallback(const geometry_msgs::Twist::ConstPtr &joy_twist)
    {
        manual_ = true;
        manual_twist_msg_.linear.x = joy_twist->linear.x;
        manual_twist_msg_.angular.z = joy_twist->angular.z;
    }
    
    void Pilot::TimerCallback(const ros::TimerEvent &event)
    {
        if(abs(manual_twist_msg_.linear.x) > 0.01 || abs(manual_twist_msg_.angular.z) > 0.01)
        {
            twist_cmd_pub_.publish(manual_twist_msg_);
            manual_ = false;
        }
        else
        {
            twist_cmd_pub_.publish(twist_msg_);
            manual_ = false;
        }
    }
    
    
    int main(int argc, char **argv)
    {
        ros::init(argc, argv, "pilot_node");
        Pilot teleop_joy;
    
        teleop_joy.timer = teleop_joy.nh_.createTimer(ros::Duration(teleop_joy.GetInterval()),
                                                        &Pilot::TimerCallback,
                                                        &teleop_joy);
        ros::spin();
    }
\end{lstlisting}

\section{Control teleoperado con Joystick}

\begin{lstlisting}[title={joy\_teleop.cpp},language=c++]
    #include <ros/ros.h>
    #include <boost/thread.hpp>
    #include <geometry_msgs/Twist.h>
    #include <geometry_msgs/TwistStamped.h>
    #include <sensor_msgs/Joy.h>
    
    class TeleopRobocar
    {
      public:
        TeleopRobocar();
    
        ros::Timer timer;
    
        ros::NodeHandle nh_;
        void timerCallback(const ros::TimerEvent &event);
        float GetInterval();
    
      private:
        void joyCallback(const sensor_msgs::Joy::ConstPtr &joy);
    
        int linear_; // axis id
        int brake_;
        int angular_;
    
        double l_scale_;
        double a_scale_;
        double l_offset_;
    
        std::string output_topic;
    
        int freq_hz_;
    
        ros::Publisher vel_pub_;
        ros::Publisher velStamped_pub_;
        ros::Subscriber joy_sub_;
    
        // for callbacks
        geometry_msgs::Twist twist;          // simple twist message from joystick
        geometry_msgs::TwistStamped stamped; // stamped twist for sync
    };
    
    TeleopRobocar::TeleopRobocar()
    {
        nh_.param<int>("freq_hz", freq_hz_, 20);
        if (freq_hz_ <= 0)
        {
            ROS_WARN("Invalid frequency value, default: 20Hz");
            freq_hz_ = 20;
        }
    
        nh_.param<int>("axis_linear", linear_, 5);
        nh_.param<int>("axis_brake", brake_, 2);
        nh_.param<double>("scale_linear", l_scale_, -0.5);
        nh_.param<double>("offset_linear", l_offset_, 0.5);
        nh_.param<int>("axis_angular", angular_, 0);
        nh_.param<double>("scale_angular", a_scale_, -1.32);    // -0.34
        nh_.param<std::string>("output_topic", output_topic, "/joy_cmd_vel");
    
        vel_pub_ = nh_.advertise<geometry_msgs::Twist>(output_topic, 1);
        velStamped_pub_ = nh_.advertise<geometry_msgs::TwistStamped>("/stamped_cmd_vel", 1);
    
        joy_sub_ = nh_.subscribe<sensor_msgs::Joy>("joy", 1, &TeleopRobocar::joyCallback, this);
    }
    
    float TeleopRobocar::GetInterval()
    {
        return 1.0 / freq_hz_;
    }
    
    void TeleopRobocar::joyCallback(const sensor_msgs::Joy::ConstPtr &joy)
    {
    
        twist.angular.z = joy->axes[angular_] * a_scale_;
    
        double acceleration = l_scale_ * joy->axes[linear_] + l_offset_;
        ROS_DEBUG("%f", acceleration);
    
        double reverse = l_scale_ * joy->axes[brake_] + l_offset_;
        ROS_DEBUG("%f", reverse);
    
        twist.linear.x = acceleration - reverse;
    
        ROS_DEBUG("%f", twist.linear.x);
    
        // vel_pub_.publish(twist);
    }
    
    void TeleopRobocar::timerCallback(const ros::TimerEvent &event)
    {
        stamped.twist = twist;
        stamped.header.stamp = ros::Time::now();
    
        vel_pub_.publish(twist);
        velStamped_pub_.publish(stamped);
    }
    
    int main(int argc, char **argv)
    {
        ros::init(argc, argv, "joy_teleop");
        TeleopRobocar teleop_joy;
    
        teleop_joy.timer = teleop_joy.nh_.createTimer(ros::Duration(teleop_joy.GetInterval()),
                                                        &TeleopRobocar::timerCallback,
                                                        &teleop_joy);
        ros::spin();
    }
\end{lstlisting}
\section{Nodo del sensor de proximidad}

\begin{lstlisting}[title={laser\_node.cpp},language=c++]
    #include "VL53L0X.h"
    #include <ros/ros.h>
    #include <sensor_msgs/Range.h> // para el sensor
    // libreria para el sensor laser
    class LaserNode
    {
      public:
        LaserNode();
    
        ros::Timer timer;
    
        ros::NodeHandle nh_;
        void timerCallback(const ros::TimerEvent &event);
        float GetInterval();
      private:
        // sensor
        VL53L0X sensor_;
    
        int freq_hz_;
        double l_scale_;
        double a_scale_;
        double l_offset_;
    
        ros::Publisher laser_pub_;
        // msgs
        sensor_msgs::Range laser_msg_;
    };
    
    LaserNode::LaserNode()
    {
        nh_.param<int>("freq_hz", freq_hz_, 20);
        if (freq_hz_ <= 0)
        {
            ROS_WARN("Invalid frequency value, default: 20Hz");
            freq_hz_ = 20;
        }
    
        // init publisher
        laser_pub_ = nh_.advertise<sensor_msgs::Range>("laser", 1);
        
        // laser
        sensor_.initialize();
        sensor_.setTimeout(200);
        
        // init some fixed data 
        laser_msg_.radiation_type = 1;
        laser_msg_.header.frame_id = "laser";
        laser_msg_.field_of_view = 0.1;
        laser_msg_.min_range = 0.0;
        laser_msg_.max_range = 1.20;
    }
    
    float LaserNode::GetInterval()
    {
        return 1.0 / freq_hz_;
    }
    
    void LaserNode::timerCallback(const ros::TimerEvent &event)
    {
        uint16_t distance = sensor_.readRangeSingleMillimeters();
    
        if (!sensor_.timeoutOccurred())
        {
            // create message and publish
            laser_msg_.range = distance / 1000.0;
            laser_msg_.header.stamp = ros::Time::now();
            laser_pub_.publish(laser_msg_);
        }
        else
        {
            ROS_WARN("Laser sensor timeout");
        }
    }
    
    int main(int argc, char **argv)
    {
        ros::init(argc, argv, "laser_node");
        LaserNode laser_node;
        
        laser_node.timer = laser_node.nh_.createTimer(ros::Duration(laser_node.GetInterval()), 
                                                    &LaserNode::timerCallback, 
                                                    &laser_node);
        ros::spin();
    }
\end{lstlisting}
