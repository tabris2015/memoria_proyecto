\chapter{Marco Teórico} \label{ch:m_teorico}

% estructura
\section{Sistemas de Conducción Autónoma}
Un sistema de conducción autónoma es una combinación de varios componentes o subsistemas donde las tareas 
de percepción, toma de decisiones y operación de un vehículo son desarrolladas por un sistema electrónico en lugar
de un conductor humano. Usualmente, un sistema de conducción autónoma incluye varios subsistemas de automatización 
que operan de manera conjunta y coordinada para poder tomar el control total o parcial del vehículo. 

En algunas ocasiones, la automía del control se implementa de manera condicional, es decir, que el sistema toma 
el control del vehículo para ciertas situaciones pero no todo el tiempo como por ejemplo sistemas de estabilización 
de frenos o prevención de impactos. Este tipo de sistemas se ha ido desarrollando e implementando en vehículos comerciales 
de manera paulatina pero todavía no existe un vehículo completamente autónomo circulando por las calles o carreteras. Notese
que los términos autonomía y automatización se usan de manera intercambiable en este contexto.

    \subsection{Niveles de Autonomía}
    Debido al creciente interés e inversión en el desarrolo de sistemas de conducción autónoma se ha establecido 
    una manera de categorizar los niveles de automatización de la conducción por parte de  la Sociedad de Ingenieros en Automoción
    (SAE, por sus siglas en inglés) en la que se definen seis niveles de automatización en vehículos terrestres, acuáticos y aéreos.

        \subsubsection{Nivel 0: Sin automatización}
        El conductor está en completo control de todas las funciones del vehículo en todo momento, no existe intervención 
        de ningún sistema automatizado en el control. Sistemas de alerta de colisión o pérdida de carril entran en esta categoría.
        \subsubsection{Nivel 1: Conducción asistida}
        El conductor tiene el control del vehículo, pero el sistema puede modificar la aceleración o dirección del mismo. Los 
        sistemas de control de velocidad de crucero caen en esta categoría.
        \subsubsection{Nivel 2: Automatización parcial}
        El conductor debe poder ser capaz de tomar el control del vehículo si ciertas se necesitan ciertas correcciones, pero  
        ya no está en control de la aceleración y dirección del vehículo directamente. Es importante resaltar que desde los
        niveles 0 al 2 el conductor no puede estar distraido en ningún momento de la conducción. Los sistemas de parqueo 
        automático representan un buen ejemplo de sistemas de Nivel 2.
        \subsubsection{Nivel 3: Automatización condicional}
        El sistema automatizado tiene el control del vehículo, tanto de la aceleración, dirección así como también del monitoreo 
        del entorno bajo condiciones específicas. El conductor debe estar preparado para intervenir cuando el sistema así lo 
        requiera, por tanto, se permiten distracciones ocasionales. Uno de los sistemas recientemente implementados que cae en esta 
        categoría es el sistema \textit{autopilot} de los vehículos de Tesla Motors. % agregar referencia
        \subsubsection{Nivel 4: Automatización elevada}
        El sistema está en completo control del vehículo y la presencia humana ya no es necesaria, sin embargo, la operación autónoma 
        del vehículo está limitada a condiciones específicas. Si las actuales condiciones del entorno sobrepasan las fronteras 
        de rendimiento definidas, el vehículo puede desplegar un protocolo o secuencia de emergencia. Actualmente el desarrollo 
        de vehículos autónomos o \textit{self driving cars} se enfoca en este nivel. 
        \subsubsection{Nivel 5: Automatización completa}
        El sistema está en completo control del vehículo y la presencia humana no es necesaria en absoluto. El sistema es capaz 
        de proveer las mismas características que en el Nivel 4, pero en esta ocasión puede operar al vehículo en todas las condiciones.
        En este nivel, el conductor pasa a ser un pasajero en el vehículo. Actualmente, no existen sistemas que operen en este nivel.

    La relación entre la responsabilidad del sistema y el conductor en los distintos niveles se puede apreciar en la 
    Tabla \ref{tbl:niveles}:
    
        \begin{table}[!h]
            \centering
            \resizebox{\textwidth}{!}{%
            \begin{tabular}{@{}|c|l|c|c|c|c|@{}}
            \toprule
            \textbf{Nivel SAE} & \textbf{Denominación}      & \textbf{\begin{tabular}[c]{@{}l@{}}Ejecución de aceleración \\ y dirección\end{tabular}} & \textbf{\begin{tabular}[c]{@{}l@{}}Monitoreo del \\ entorno\end{tabular}} & \textbf{\begin{tabular}[c]{@{}l@{}}Responsable en \\ condiciones difíciles\end{tabular}} & \textbf{\begin{tabular}[c]{@{}l@{}}Modos de \\ conducción\end{tabular}} \\ \midrule
            0                  & Sin Automatización         & Humano                                                                                   & \multirow{3}{*}{Humano}                                                   & \multirow{4}{*}{Humano}                                                                  & Ninguno                                                                 \\ \cmidrule(r){1-3} \cmidrule(l){6-6} 
            1                  & Conducción asistida        & Humano y sistema                                                                         &                                                                           &                                                                                          & \multirow{3}{*}{Algunos Modos}                                          \\ \cmidrule(r){1-3}
            2                  & Automatización parcial     & \multirow{4}{*}{Sistema}                                                                 &                                                                           &                                                                                          &                                                                         \\ \cmidrule(r){1-2} \cmidrule(lr){4-4}
            3                  & Automatización condicional &                                                                                          & \multirow{3}{*}{Sistema}                                                  &                                                                                          &                                                                         \\ \cmidrule(r){1-2} \cmidrule(l){5-6} 
            4                  & Automatización elevada     &                                                                                          &                                                                           & \multirow{2}{*}{Sistema}                                                                 & Varios Modos                                                            \\ \cmidrule(r){1-2} \cmidrule(l){6-6} 
            5                  & Automatización completa    &                                                                                          &                                                                           &                                                                                          & Todos los Modos                                                         \\ \bottomrule
            \end{tabular}%
            }
            \caption{Niveles de automatización según SAE. Fuente: SAE} % TODO: referencia
            \label{tbl:niveles}
            \end{table}

    \subsection{Arquitectura de un sistema de conducción autónoma}
    % \subsection{Aprendizaje Profundo}

% TODO: 
\section{Visión por computador}
-
    \subsection{Procesamiento de imágenes}
    \subsection{Filtrado}

\section{Redes Neuronales Artificiales}

    \subsection{Aprendizaje Automático}
    El aprendizaje automático es un subcampo de la inteligencia artificial que intenta extraer 
    patrones mediante un proceso de \textit{aprendizaje} a partir de datos \cite{Mitchell1990}. Este proceso 
    de aprendizaje se define de acuerdo a una \textbf{tarea específica} $T$ que intenta aprenderse en base 
    a \textbf{experiencia pasada} $E$ tomando como referencia una \textbf{medida de rendimiento} $P$ . 
    Dentro de esta definición, se puede listar varios ejemplos de tareas de aprendizaje que usualmente se resuelven  
    usando los conceptos del aprendizaje automático o también llamado \textit{machine learning}:
    \\
    \\
    \begin{itemize}
        \item \textbf{Un algoritmo de aprendizaje que pueda jugar ajedrez:}
        \begin{itemize}
            \item \textbf{Tarea $T$:} Jugar Ajedrez.
            \item \textbf{Medida de Rendimiento $P$:} Porcentaje de partidas ganadas contra el oponente.
            \item \textbf{Experiencia $E$:} Información de varias partidas de práctica.
        \end{itemize}
        
        \item \textbf{Un algoritmo de aprendizaje que pueda reconocer dígitos manuscritos:}
        \begin{itemize}
            \item \textbf{Tarea $T$:} Reconocer y clasificar dígitos manuscritos dentro de una imagen.
            \item \textbf{Medida de Rendimiento $P$:} Porcentaje de dígitos correctamente clasificados.
            \item \textbf{Experiencia $E$:} Base de datos de imágenes de dígitos con sus etiquetas correspondientes.
        \end{itemize}

        \item \textbf{Un algoritmo de aprendizaje que pueda reconocer la voz:}
        \begin{itemize}
            \item \textbf{Tarea $T$:} Extraer una secuencia de palabras de una grabación de voz.
            \item \textbf{Medida de Rendimiento $P$:} Porcentaje de palabras correctamente predichas.
            \item \textbf{Experiencia $E$:} Grabaciones de voz con una transcripción correspondiente.
        \end{itemize}
    
    \end{itemize}
    

    Esta definición de aprendizaje es lo suficientemente amplia como para englobar todas las tareas 
    que el campo del aprendizaje automático intenta resolver en la actualidad. Sin embargo, debido a 
    su naturaleza, se pueden clasificar las tareas de aprendizaje en tres grandes categorías que tienen
    características particulares: aprendizaje supervisado, aprendizaje no supervisado y aprendizaje por refuerzo.

    La diferencia entre estos tres tipos de problemas surge de la distinta naturaleza de la experiencia $E$ disponible
    para el entrenamiento. A continuación, se procede a detallar cada uno de ellos.

        \subsubsection{Aprendizaje supervisado} \label{sss:supervisado}
        En el caso de las tareas de aprendizaje supervisado, la experiencia constituye un conjunto de datos o \textit{dataset}
        que contiene ejemplos con \textit{características} y cada ejemplo está asociado con una \textit{etiqueta}. Por ejemplo, 
        un conjunto de datos de flores donde cada registro contiene datos de la flor (características) y la especie a la que pertenece (etiqueta). 
        Dentro de los algoritmos que atacan problemas de aprendizaje supervisado se pueden encontrar 2 grandes categorías.
            \paragraph{Clasificación}
            Las tareas de clasificación tienen como característica el hecho de que la etiqueta de cada ejemplo en el 
            conjunto de datos pertenece a una categoría o, en otras palabras, tiene una naturaleza discreta y finita. Por ejemplo, 
            en el caso de la clasificación de las flores mencionado anteriormente, la etiqueta solamente puede pertenecer a un
            conjunto finito de especies de flores y cada ejemplo pertenece a una de estas especies.
            \paragraph{Regresión}
            En las tareas de regresión, las etiquetas pertenecen a un conjunto de números reales o de naturaleza 
            contínua. En este caso, las etiquetas no se asocian con categorías sino más bien con otro tipo de variables. Un 
            ejemplo muy conocido es el de la tarea de la predicción del precio de una casa en base a sus características, el precio 
            de una casa no puede categorizarse porque representa un número que puede tener infinitos valores dentro de un rango definido.
        
        En las tareas del aprendizaje supervisado, se puede considerar cada ejemplo como una descripción de 
        una situación (características) en conjunto con una especificación (etiqueta), cada uno de los ejemplos 
        dentro el conjunto de datos son eventos independientes y se pueden analizar por separado. En este sentido
        la tarea del algoritmo es generalizar la respuesta para casos no presentes en el conjunto inicial de datos.

        \subsubsection{Aprendizaje no supervisado}
        En las tareas del aprendizaje no supervisado la experiencia contenida en el conjunto de datos tiene la característica de 
        no poseer ninguna etiqueta, por tanto, usualmente se intenta buscar una estructura escondida dentro el conjunto de datos 
        o, dicho de otra manera, se buscan patrones que puedan presentarse en dichos datos. Estos patrones pueden aprovecharse 
        para extraer información relevante de la naturaleza de datos de muy alta dimensionalidad, información que normalmente no 
        es trivial de encontrar o visualizar por una persona. Entre algunas de las tareas más comunes dentro del aprendizaje no 
        supervisado, se pueden listar:

            \paragraph{Clustering}
            Refiere a la tarea de separar y agrupar los datos en un número finito de conjuntos o \textit{clusters}. Los 
            \textit{clusters} normalmente denotan una estructura oculta dentro de los datos y proporcionan información acerca 
            de la similaridad entre ejemplos del conjunto de datos.

            \paragraph{Reducción de dimensionalidad}
            Uno de los problemas con las bases de datos y conjuntos de datos disponibles es que poseen una dimensionalidad 
            bastante alta haciendo prácticamente imposible para un humano poder visualizar o encontrar patrones e información 
            útil en los mismos. Este problema se suele tratar con algoritmos de reducción de dimensionalidad, en la que 
            se encuentra una representación estimada de los datos pero con menos dimensiones. Uno de los algoritmos más 
            conocidos y usados en esta categoría es el análisis de componente principal o PCA, por sus siglas en inglés, en el 
            que se encuentra una representación de los datos en una menor dimensión usando proyecciones ortogonales.

            \paragraph{Estimación de probabilidad}
            Muchos conjuntos de datos son obtenidos de distintas fuentes y a lo largo de varios intervalos de tiempo, en este 
            entendido, es muy útil conocer o aproximar la distribución de probabilidad de los datos para luego poder realizar 
            predicciones o tratarlos con algún modelo en específico.

        \subsubsection{Aprendizaje por refuerzo}
        En las tareas de aprendizaje por refuerzo se toma en cuenta la interacción de un agente con su entorno y la forma 
        en la que las acciones que toma dicho agente afectan a su entorno y se materializan en una recompensa o castigo \cite{sutton2018reinforcement}. Formalmente
        se pueden definir ciertos elementos que componen una tarea de aprendizaje por refuerzo:
        \begin{itemize}
            \item \textbf{Agente.} Es la entidad que interactúa con el entorno. El agente se comunica con el entorno mediante acciones.
            \item \textbf{Política.} Representan la forma de actuar del agente en base al conocimiento que ha adquirido.
            \item \textbf{Recompensa.} Es la función que define la efectividad del agente de cumplir el objetivo deseado, normalmente, el aprendizaje se enfoca en maximizar la recompensa que el agente puede obtener. 
        \end{itemize}
        
        % TODO: insertar grafico de aprendizaje por refuerzo

    % TODO: 
    \subsection{Aprendizaje Profundo}
    Dentro del campo de la inteligencia artificial y el aprendizaje automático se han implementado diversos tipos 
    de algoritmos con éxito en los tipos de tareas de aprendizaje mencionados anteriormente. La base teórica y los detalles 
    de implementación de estos algoritmos son muy variados, sin embargo, las redes neuronales artificiales han experimentado 
    un incremento en el interés en la investigación y en las aplicaciones muy importante. Tal es el éxito de las mismas 
    que se ha creado un subcampo exclusivo llamado aprendizaje profundo o \textit{deep learning}. El aprendizaje profundo 
    es un campo de la inteligencia artificial que se encarga de estudiar exclusivamente a las redes neuronales artificiales, 
    sus componentes, arquitectura y aplicaciones. El impresionante rendimiento de estos algoritmos reside principalmente en el 
    concepto de la representación que generan a partir de los datos que se procesan. 

    El aprendizaje profundo resuelve el problema del aprendizaje de representaciones al introducir representaciones que se 
    expresan en términos de otras representaciones más simples. Además, permite a una computadora construir conceptos complejos 
    a partir de conceptos más simples. Un ejemplo de la generación de estos conceptos o representaciones se puede apreciar en la 
    Figura(\ref{fig:representacion}).
    
    
    \begin{figure}[!h] 
        \centering
        \includegraphics[width=0.75\textwidth]{img/representacion}
        \caption{Ilustración de un modelo de aprendizaje profundo. Las representaciones se generan en las capas ocultas y corresponden con características de distintos niveles de complejidad. Fuente: \cite{Goodfellow-et-al-2016} }
        \label{fig:representacion}
    \end{figure}

    A continuación, se procede a definir los conceptos más importantes de redes neuronales artificiales con los cuales se podrá 
    plantear la solución al problema de la conducción autónoma usando visión artificial.

        \subsubsection{Redes neuronales feedforward}
        Las redes neuronales feedforward o también llamadas perceptrón multicapa, son la base fundamental de los modelos 
        de aprendizaje profundo. El objetivo de una red neuronal feedforward es el de aproximar una función $f^\ast$. Por 
        ejemplo, para una tarea de clasificación, $y = f^\ast (\mathbf{x})$ mapea una entrada $\mathbf{x}$ a una categoría $y$.
        Una red neuronal feedforward define un mapeo $\mathbf{y} = f(\mathbf{x},\mathbf{W})$ y aprende el valor de los parámetros 
        $\mathbf{W}$ que resulten en la mejor aproximación\cite{Goodfellow-et-al-2016}.

        Este tipo de modelos son denominados feedforward debido a que la información fluye a por la función siendo evaluada 
        desde $\mathbf{x}$, a través de distintos cálculos intermedios definidos por $f$, hasta llegar a la salida $\mathbf{y}$.
        No existen conexiones de retroalimentación en las que la salidas del modelo se inyecten de nuevo a sí mismo. Las redes 
        neuronales que poseen este tipo de conexiones de retroalimentación son denominadas redes neuronales recurrentes.

        Para definir una red neuronal feedforward se puede comenzar definiendo un modelo basado en una combinación 
        lineal en conjunto con una función no lineal que toma la siguiente forma:

        \begin{equation}\label{eq:modelobase}
            y(\mathbf{x}, \textbf{W}) = f\left(\sum_{j=1}^M w_j  x_j\right)
        \end{equation}

        donde $f()$ es una función de activación no lineal. Esto lleva al modelo básico de una red neuronal que puede ser 
        descrita como una serie de transformaciones. Primero, se construyen $M$ combinaciones lineales de las variables 
        de entrada $x_1, \ldots , x_D$ donde $D$ es la dimensión del vector de entrada $\mathbf{x}$:
        
        \begin{equation}
            a_j = \sum_{i=1}^D w_{ji}^{(1)} x_i + w_{j0}^{(1)}
        \end{equation}

        donde $j = 1, \ldots , M$, y el superíndice $(1)$ indican que los correspondientes parámetros se encuentran en la 
        primera capa de la red. Los parámetros $w_{ji}^{(1)}$ se suelen conocer también con el nombre de \textit{pesos} y 
        los parámetros $ w_{j0}^{(1)}$ con el nombre de \textit{sesgos} o \textit{biases}. Las cantidades $a_j$ se conocen 
        como \textit{activaciones}, y cada una de ellas es luego transformada usando una función no lineal y derivable conocida 
        como la \textit{función de activación} $h()$ para luego obtener:

        \begin{equation}
            z_j = h(a_j)
        \end{equation}

        Estas cantidades corresponden con la salida de la capa y también se suelen referir por el nombre de  \textit{unidades ocultas}.
        Las funciones no lineales $h()$ pueden escogerse dependiendo a diversos criterios de rendimiento o de comportamiento. Siguiendo
        a la Ecuación(\ref{eq:modelobase}), las unidades ocultas se pueden volver a procesar con una combinación lineal y función 
        de activación en una segunda capa:

        \begin{equation}
            a_k = \sum_{j=1}^M w_{kj}^{(2)} z_j + w_{k0}^{(2)}
        \end{equation}

        donde $k = 1, \ldots, K$ y $K$ corresponden con el número de salidas de la segunda capa. Finalmente, si se considera a 
        esta capa como la capa de salida, podemos transformar las activaciones de la segunda capa con una función de activación. 
        Normalmente, para una tarea de regresión, la función de activación es una función identidad, es decir $y_k = a_k$. Para 
        una tarea de clasificación binaria, en cambio, la función de activación es una función sigmoide:

        \begin{equation}
            y_k = \sigma(a_k)
        \end{equation}

        donde
        
        \begin{equation}\label{eq:sigmoide}
            \sigma(a) = \frac{1}{1 + e^{-a}}    
        \end{equation}
        
        Finalmente, se pueden combinar las etapas en una función general de la red que, para una salida sigmoidal, toma la 
        siguiente forma:

        \begin{equation}\label{eq:reddoscapas}
            y_k(\mathbf{x}, \mathbf{W}) = \sigma \left( \sum_{j=1}^M w_{kj}^{(2)} h \left( \sum_{i=1}^D w_{ji}^{(1)} x_i + w_{j0}^{(1)} \right) + w_{k0}^{(2)} \right)
        \end{equation}

        De esta manera, se define una red neuronal de dos capas a partir de la combinación lineal de las entradas y las unidades 
        ocultas con los parámetros o pesos de la red transformados por funciones de activación no lineal. La arquitectura de la 
        red definida en la Ecuación(\ref{eq:reddoscapas}) se puede visualizar en la Figura(\ref{fig:reddoscapas}) donde se observa claramente las relaciones que se 
        han definido anteriormente en forma gráfica y la naturaleza del flujo en una sola dirección (feerforward) de los datos 
        desde la entrada hasta la salida. En este caso, la red neuronal analizada es una red neuronal con una capa oculta.

        \begin{figure}[!h] 
            \centering
            \includegraphics[width=0.75\textwidth]{img/reddoscapas}
            \caption{Diagrama de la red neuronal de dos capas correspondiente a la Ecuación(\ref{eq:reddoscapas}). Fuente: \cite{Bishop2006} }
            \label{fig:reddoscapas}
        \end{figure}
        
        \subsubsection{Funcion de costo}
        La función de costo es una función que permite definir el rendimiento de una red neuronal con respecto a las 
        predicciones esperadas a la salida. Un aspecto importante en el diseño de una red neuronal es la elección adecuada 
        de la función de costo. 

        La función de costo o función de error, se define de manera similar al caso del ajuste de curvas. Es decir, se desea 
        minimizar una suma de errores cuadráticos. Dado un conjunto de entrenamiento compuesto por un conjunto de vectores 
        de entrada $\{\mathbf{x}_n \}$, donde $n = 1, \ldots , N$, junto con un conjunto de vectores objetivo $\{\mathbf{t}_n \}$
        el objetivo es minimizar la función:

        \begin{equation}\label{eq:error}
            E(\mathbf{w}) = \frac{1}{2} \sum_{n=1}^N \{y(\mathbf{x}_n, \mathbf{w}) - t_n\}^2
        \end{equation}

        donde el valor de $\mathbf{w}$ que minimice la función de error $E(\mathbf{w})$ será considerado como el mejor conjunto 
        de parámetros sobre el cual el modelo puede generalizar.

        \subsubsection{Entrenamiento usando gradientes y retropropagación} \label{sec:gradientes}

        Una vez definidos con claridad los componentes básicos de una red neuronal feedforward y cómo es el proceso del flujo 
        de la información desde la entrada $\mathbf{x}$ hasta la salida $\mathbf{y}$, solamente queda especificar el procedimiento 
        necesario para ajustar los parámetros o pesos de la red $\mathbf{W}$. Para este cometido, el método más usado es el 
        de la retropropagación o \textit{backpropagation}, popularizado a partir del paper de Rumelhart \cite{rumelhart1986learning} 
        y ampliamente usado en la actualidad en la mayoría de las redes neuronales. La retropropagación tiene el objetivo de 
        encontrar los gradientes, en específico, se desea encontrar el gradiente de de la función de costo o error con respecto 
        a los parámetros $\nabla_{\mathbf{W}}E(\mathbf{W})$. Si tomamos en cuenta que una red neuronal feedforward puede tener 
        varias capas ocultas, la gradiente de la función de costo está en función de los parámetros y funciones de activación 
        de cada capa, por tanto, se necesita usar la regla de la cadena para poder encontrar estos gradientes intermedios.

        Sea $y = g(x)$ y $z = f(g(x)) = f(y)$ dos funciones reales con argumento real, la regla de la cadena define lo siguiente:

        \begin{equation}
            \frac{dz}{dx} = \frac{dz}{dy} \frac{dy}{dx}
        \end{equation}

        Se puede generalizar la anterior expresión para casos fuera de una variable escalar donde $x \in \mathbb{R}^m$, 
        $y \in \mathbb{R}^n$, $g$ mapea de $\mathbb{R}^m$ a $\mathbb{R}^n$ y $f$ mapea de $\mathbb{R}^m$ a $\mathbb{R}$,
        si $\mathbf{y} = g(\mathbf{x})$ y $\mathbf{z} = g(\mathbf{y})$, entonces:

        \begin{equation}
            \frac{dz}{dx_i} =\sum_j \frac{dz}{dy_j} \frac{dy_j}{dx_i}
        \end{equation}

        en notación vectorial, sería equivalente a lo siguiente:

        \begin{equation}
            \nabla_{\mathbf{x}}z = \left( \frac{\partial \mathbf{y}}{\partial \mathbf{x}} \right)^T \nabla_{\mathbf{y}} z
        \end{equation}

        donde $\frac{\partial \mathbf{y}}{\partial \mathbf{x}}$ es el jacobiano $n \times m$ de $g$. Lo importante aqui 
        es recordar que en una función multivariable, el gradiente proporciona la dirección hacia donde la función crece 
        más rapidamente, esta intuición es fundamental para poder actualizar los pesos de la red en una etapa posterior.

        El concepto fundamental de la retropropagación es encontrar estos gradientes de manera secuencial, partiendo desde 
        la capa de salida hasta llegar a la capa de entrada. 

            \paragraph{Actualización de los parámetros de la red}
            La importancia de hallar los gradientes de la red con respecto a los pesos reside en que son justamente 
            los gradientes los que proporcionan la información de la evolución de los pesos con respecto de la función 
            de error y en qué dirección se encuentra el mínimo. En la Figura(\ref{fig:gradsup}) se puede ver cómo, para 
            una combinación arbitraria de pesos $\mathbf{w}_C$ el gradiente de la función de error $\nabla E$ indica 
            la direccion de máximo crecimiento de la superficie

            \begin{figure}[!h] 
                \centering
                \includegraphics[width=0.75\textwidth]{img/gradsup}
                \caption{Visualización de la función de error $E(\mathbf{w})$ como una superficie. El punto $\mathbf{w}_A$ es un mínimo local y el punto $\mathbf{w}_B$ es el mínimo global. Fuente: \cite{Bishop2006} }
                \label{fig:gradsup}
            \end{figure}

            La actualización de los parámetros dados los gradientes de la red se puede realizar de distintas formas, pero una 
            de las más comunes es el algoritmo llamado \textit{Descenso de gradiente}, donde, de forma iterativa, se 
            va actualizando los pesos restando una medida del gradiente de la siguiente manera:

            Dicho de otro modo, en el descenso de gradiente, se avanza un pequeño paso en la dirección opuesta al gradiente 
            para avanzar hacia el mínimo:

            \begin{equation}
                \mathbf{w}^{(\tau + 1)} = \mathbf{w}^{(\tau)} - \alpha \nabla E(\mathbf{w}^{(\tau)})
            \end{equation}

            donde el parametro $\alpha > 0$ se conoce como la razón de aprendizaje o \textit{learning rate}. Después de 
            cada actualización, el gradiente es recalculado para poder encontrar los nuevos pesos y el proceso se repite 
            hasta encontrar el punto donde $\nabla E = 0$, lo que quiere decir que se ha llegado al mínimo. Usualmente, por 
            la naturaleza de la superficie de la función de error y diversos errores en el cálculo en una computadora, el número 
            de iteraciones se limita en base a cierto parámetro de rendimiento.

        \subsubsection{Funciones de activación}
        Se ha estudiado con mucho detalle la naturaleza de la función de activación $f()$, introducida en la 
        Ecuación(\ref{eq:modelobase}), analizando fundamentalmente dos aspectos: su contribución a la generación 
        de representaciones internas en las capas ocultas de la red neuronal, así como también su comportamiento 
        de sus gradientes con relación a la etapa de aprendizaje, tal como se ha visto en la Sección(\ref{sec:gradientes}), 
        donde se ha establecido claramente que el papel de la función de activación y sus gradientes es fundamental para 
        el proceso de retropropagación y ajuste de los pesos de la red. Una guía con algunos criterios puede 
        encontrarse en \cite{mhaskar1994choose}, de donde se rescatan los siguientes aspectos a la hora de escoger una 
        función de activación:
        \begin{itemize}
            \item Que modele de forma no lineal la naturaleza de una representación interna fácil de interpretar.
            \item Que sea derivable en todo el rango de trabajo.
        \end{itemize}

        Tomando en cuenta lo anterior, se han generado diversas tendencias en la aplicación de funciones de activación y a 
        continuación se analizarán las más relevantes para este proyecto.
            \paragraph{Función sigmoide}\label{sec:sigmoide}
            Esta función ha sido introducida en la Ecuación(\ref{eq:sigmoide}) y representa, históricamente, la función 
            más utilizada en las primeras redes neuronales artificiales porque modela de manera aproximada, una respuesta 
            característica de las neuronas del cerebro \cite{narayan1997generalized}, pero sobre todo, porque posee las dos características mencionadas 
            anteriormente: naturaleza no lineal y diferenciable. Otra característica llamativa, es que se puede interpretar 
            a la salida como una función de probabilidad, pues sus valores van desde $0$ a $1$, como se puede apreciar 
            en la Figura(\ref{fig:sigmoide}). Usualmente se incluye un parámetro adicional para controlar el \textit{radio de activación}
            que hace que la función responda con más o menos sensibilidad a su entrada.

            \begin{figure}[!h] 
                \centering
                \includegraphics[width=0.75\textwidth]{img/sigmoide}
                \caption{Gráfico de la función sigmoide $\sigma(v) = 1 / (1 + e^{(-v)})$ (curva roja), y dos variaciones con un radio de activación de la forma $\sigma(sv)$ con valores $s=1/2$ (curva azul) y $s=10$ (curva púrpura) . Fuente: \cite{Goodfellow-et-al-2016} }
                \label{fig:sigmoide}
            \end{figure}
            
            Pese a las características anteriormente mencionadas, la función sigmoide tiene una gran desventaja: el llamado 
            \textit{desvanecimiendo de gradientes} \cite{hochreiter1998vanishing}. Este fenómeno ocurre cuando la activación 
            de una capa oculta tiene valores muy altos o muy negativos, se puede apreciar en la Figura(\ref{fig:sigmoide}), que 
            para estos valores, la derivada tiene un valor muy pequeño, aproximándose a cero mientras más grandes sean los valores.
            Este fenómeno ocasiona que, mientras se realiza la retropropagación de gradientes, dado que el gradiente tiene un valor 
            muy bajo, el ajuste en los pesos sea mínimo, deteniendo así el aprendizaje de la neurona en la que ocurre el fenómeno.

            Esta dificultad se presenta especialmente cuando la red neuronal se compone de varias capas ocultas y 
            ha motivado el desarrollo de nuevas funciones de activación que no presenten esta limitación y puedan 
            mantener valores de gradientes adecuados durante el entrenamiento.
            
            Cabe resaltar que, pese a las dificultades con la propagación de los gradientes de la función sigmoide, ésta se suele 
            utilizar bastante en la capa de salida, cuando se trata de clasificación binaria, ya que representa de manera adecuada
            la noción de probabilidad, lo cual es deseable en este tipo de modelos.

            \paragraph{Función tangente hiperbólica} \label{sec:tanh}
            La función tangente hiperbólica o $tanh()$ se define mediante la siguiente expresión:

            \begin{equation}\label{eq:tanh}
                tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}
            \end{equation}

            Esta función también cumple con los requisitos de no linealidad y de ser derivable, pero en este caso, el rango de 
            salida de la función $tanh()$ es desde $-1$ a $1$. Considerando el concepto de función de probabilidad que ofrece 
            la salida de la función sigmoide, la función tangente hiperbólica introduce el concepto de aceptación o negación 
            de una premisa, donde una premisa aceptada se acerca a 1 y una premisa rechazada se acerca a -1, el valor de 0, 
            indica indecisión. La función $tanh()$ se ha usado junto a su par sigmoide ampliamente en los inicios de las redes 
            neuronales para las activaciones de las capas ocultas, pero, tal como se puede observar en la Figura(\ref{fig:tanh}), 
            presenta la misma desventaja del desvanecimiendo de gradientes, dado que para valores muy grandes, la derivada se 
            aproxima a cero.

            \begin{figure}[!h] 
                \centering
                \includegraphics[width=0.75\textwidth]{img/tanh}
                \caption{Gráfico de la función tangente hiperbólica $tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}$. Fuente: \cite{wang_2016} }
                \label{fig:tanh}
            \end{figure}

            En la actualidad, para implementaciones de redes neuronales profundas, el uso de las funciones sigmoide y tangente 
            hiperbólica en las capas ocultas está ampliamente desaconsejado por los problemas anteriormente planteados. En su 
            lugar se ha generado nuevos tipos de funciones de activación que presentan características bastante favorables 
            para el aprendizaje y ajuste de pesos basados en gradientes.

            \paragraph{Unidad Lineal Rectificada - ReLU}
            Introducida por primera vez en el año 2010 por Nair y Hinton, las Unidades Lineales Rectificadas o ReLU, se 
            propusieron para mejorar el rendimiento de un tipo especial de red neuronal: las máquinas restringidas de Boltzman 
            (RMB, por sus siglas en inglés) \cite{nair2010rectified}, pero pronto, ganarían gran popularidad también en las 
            redes neuronales feedforward y en redes neuronales convolucionales como se puede apreciar en \cite{krizhevsky2012imagenet}.
            
            La función ReLU se define de la siguiente manera:

            \begin{equation}\label{eq:relu}
                g(x) = max\{0,x\}
            \end{equation}

            Tal como se puede apreciar, la característica más importante de la función ReLU es su simplicidad pues es muy 
            similar a una función identidad, la diferencia es que ReLU toma el valor de cero para todos los valores de $x$ que 
            sean negativos. Esto resuelve el problema del desvanecimiendo de gradientes pues garantiza que el gradiente 
            tenga un valor razonable si la entrada está activa y además sea consistente.

            \begin{figure}[!h] 
                \centering
                \includegraphics[width=0.75\textwidth]{img/relu}
                \caption{Gráfico de la ReLU. Fuente: \cite{wang_2016} }
                \label{fig:relu}
            \end{figure}

            Sin embargo, dado que la función ReLU tiene una gradiente nula para valores negativos es de vital importancia 
            que se garantice la existencia de gradientes positivos, aunque sea pequeños durante la inicialización y las capas 
            previas.

        \subsubsection{Diseño de Arquitecturas}

    \subsection{Redes Neuronales Convolucionales}
    Las redes neuronales convolucionales son un tipo especializado de red neuronal que 
    sirven para procesar datos de tipo "grilla" \cite{Goodfellow-et-al-2016}. Algunos ejemplos 
    de datos de tipo grilla que se pueden mencionar son los siguientes:
    \begin{itemize}
        \item \textbf{Series de tiempo.} Grilla de una dimensión tomados en intervalos regulares de tiempo.
        \item \textbf{Imágenes digitales.} Grilla de pixeles de dos o más dimensiones (Escala de grises, RGB).
    \end{itemize}

    Las también llamadas redes convolucionales, han demostrado un éxito impresionante en diversas 
    aplicaciones prácticas especialmente en el campo de la visión por computador y el procesamiento de texto y lenguaje natural. 
    El término ``red neuronal convolucional'' proviene del hecho de que en este tipo 
    de redes neuronales se utiliza una operación matemática llamada \textbf{convolución}, siendo la convolución 
    una operación lineal especializada para procesar datos de tipo grilla.

    En los párrafos posteriores, se procede a describir la operación de convolución en el contexto de 
    redes neuronales, pues, no siempre la definición de la misma corresponde con el concepto de convolución
    usado en distintos campos de la ciencia y la ingeniería.

        \subsection{Operación de convolución}
        En su forma más general, la convolución es una operación entre dos funciones reales y su definición se puede introducir
        usando el concepto de un promedio ponderado. Sea una función $x(t)$ dependiente del tiempo, 
        tanto $x$ como $t$ son números reales; en este caso, la función $x$ puede entenderse como una serie de medidas
        en un instante de tiempo $t$. Considérese una segunda función de ponderación $w(\tau)$ donde $\tau$ es la antiguedad 
        de una medida. Si se aplica la función de ponderación en cada instante de tiempo, se puede obtener una nueva función 
        definida por:
        \begin{equation}
            s(t) = \int x(\tau)w(t - \tau) d\tau
        \end{equation} 
        Esta operación es llamada la \textit{operación de convolución} y es denotada tradicionalmente con un asterisco:
        \begin{equation}
            s(t) = (x\ast w)(t)
        \end{equation}
        En el ejemplo de la ponderación, $w$ debe ser una función de densidad de probabilidad válida, o la salida no podrá
        ser considerada como un promedio ponderado. Además, $w$ también debe ser $0$ para cualquier $t<0$, esta última 
        característica se denomina comunmente como el principio de ``causalidad''. En general, la convolución está 
        definida para cualquier función en la cual la integral anteriormente declarada esté definida y puede ser 
        usada para otros propósitos aparte de promedios ponderados.

        Hablando en términos de una red neuronal convolucional, el primer argumento (en el ejemplo, la función $x$) 
        es comunmente referido como la \textbf{entrada}, y el segundo argumento ($w$, en el ejemplo) es referido 
        como el \textbf{kernel}. La salida, a su vez, es normalmente referida como el \textbf{mapa de características}.
        
        Por su parte, cuando se trata de señales digitales, como los datos en una computadora, el tiempo tiene una 
        naturaleza discreta, es decir, que los datos estarán disponibles en intervalos regulares de tiempo. En este 
        caso, el índice de tiempo $t$ puede tomar solamente valores enteros y, entonces, es válido asumir 
        que tanto $x$ como $w$ estan definidos solamente para valores enteros de $t$. De este modo, 
        se puede definir la convolución discreta:
        \begin{equation}
            s(t) = (x \ast w)(t) = \sum_{\tau=-\infty}^{\infty}x(\tau)w(t-\tau)
        \end{equation}

        En el contexto de las aplicaciones de aprendizaje automático o, más específicamente, aprendizaje profundo,
        la entrada es usualmente un arreglo multidimensional de datos, y el kernel es usualmente un arreglo 
        multidimensional de parámetros que se adaptan en el proceso de aprendizaje. 

        \subsubsection{Procesamiento de imágenes con redes neuronales convolucionales}

        % TODO: poner un grafico de la convolucion en 2d de una imagen 


        La operación de convolución se usa frecuentemente sobre datos con más de una dimensión. Las imágenes digitales 
        son un perfecto ejemplo de un arreglo multidimensional de datos. Una imagen digital se representa mediante una
        matriz con filas y columnas, donde cada elemento se denomina pixel y contiene información acerca de la intensidad
        o luminancia, para una imagen en escala de grises o el nivel de color para distintos canales en una imagen a color.
        Si se toma el ejemplo de la imagen en escala de grises, se tiene una entrada o imagen bidimensional $I$ con un
        kernel bidimensional correspondiente $K$:

        \begin{equation} \label{eq:conv2d}
            S(i,j)=(I\ast K)(i,j) = \sum_{m} \sum_{n} I(m,n)K(i-m,j-n)
        \end{equation}

        Dado que la convolución es conmutativa, se puede reescribir la ecuación \ref{eq:conv2d} como:

        \begin{equation}
            S(i,j)=(K\ast I)(i,j) = \sum_{m} \sum_{n} I(i-m,j-n)K(m,n)
        \end{equation}

        Frecuentemente, la última fórmula es la más utilizada en librerías de aprendizaje profundo 
        por su sencillez en la implementación en un sistema computacional, esto, dado que existe menos 
        variación en el rango de valores válidos de $m$ y $n$.

        \subsubsection{Aprendizaje de representaciones internas}
        Una de las preguntas clave en la visión por computador es el cómo generar una buena y significativa
        representación interna de una imagen, dado que la mayor parte de la imagen corresponde con pixeles que no 
        aportan mucha información relevante a la tarea asignada. Por ejemplo, si se quisiera detectar 
        un rostro dentro de una imagen, normalmente se suele encontrar una representación que ayude a aislar solamente 
        las porciones de la imagen que pueden contener el rostro, tales como la búsqueda de contornos, bordes y 
        características típicas de un rostro. Antes de la aparición de las redes convolucionales, estas representaciones 
        se hallaban de manera manual y gracias al conocimiento de expertos en el área del procesamiento de imágenes. 
        La definición de características y mapas de características era comunmente conocida como la 
        \textit{ingeniería de características}, en la cual los expertos creaban descriptores para tareas específicas con 
        una gran inversión de tiempo en la sintonización fina de los mismos. 

        % TODO: poner el ejemplo de viola jones 

        En contraste con el anterior enfoque, las redes convolucionales generan sus propias representaciones internas
        de manera automática gracias al aprendizaje de los parámetros de cada uno de los kernels que componen las distintas 
        capas de la red neuronal. En principio, las redes convolucionales se inspiraron en el trabajo de Hubel y Wiesel 
        sobre la corteza visual primaria de un gato\cite{lecun2010convolutional}. En dicho trabajo, se logró identificar células simples que respondían
        de manera sobresaliente a distintas orientaciones con campos receptivos locales. Éstas células receptivas simples 
        se pueden corresponder con los kernels de convolución usados en las redes convolucionales por la sencillez y la 
        localidad de su campo de receptividad.

        Posteriormente, las redes convolucionales ganaron una gran popularidad debido a su rendimiento en tareas de 
        clasificación de imágenes y detección y reconocimiento de objetos en imágenes. El primer hito de su capacidad 
        para procesar imágenes de manera efectiva fue en concurso de clasificación de imágenes de ImageNet, donde 
        el equipo de Geoffrey Hinton logró sobrepasar el mejor resultado en precisión de clasificación por un gran márgen 
        usando una arquitectura de red convolucional \cite{krizhevsky2012imagenet}. En este trabajo, se pudo apreciar con 
        gran detalle las ventajas del enfoque del aprendizaje de representaciones internas en una red convolucional.

        \begin{figure}[!h] 
            \centering
            \includegraphics[width=0.75\textwidth]{img/fmap_imagenet}
            \caption{Kernels convolucionales de tamaño $11 \times 11 \times 3$ en la primera capa convolucional. Fuente: \cite{krizhevsky2012imagenet} }
            \label{fig:fmap_imagenet}
        \end{figure}
            
        Tal como se puede apreciar en la Figura(\ref{fig:fmap_imagenet}), en la primera capa convolucional, 
        los kernels de convolución corresponden con representaciones básicas en una imagen como la búsqueda de 
        bordes en distintas orientaciones, esto va acorde a lo establecido anteriormente en el modelo de 
        la corteza visual de un gato. Puede decirse entonces que las redes convolucionales emulan, en cierto modo, 
        al proceso biológico de visión en animales.

    % TODO: 
    \subsection{Sistemas de Aprendizaje Fin a Fin}

\section{Modelo cinemático del vehículo}
-
    \subsection{Ecuaciones de movimiento}


